{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5a0b64f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.26793439515500544\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "module 'kfp.components' has no attribute 'create_deployment'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 58\u001b[0m\n\u001b[0;32m     55\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m deployment, service\n\u001b[0;32m     57\u001b[0m \u001b[38;5;66;03m# Create a pipeline\u001b[39;00m\n\u001b[1;32m---> 58\u001b[0m \u001b[38;5;129m@pipeline\u001b[39m(name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMNIST training pipeline\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     59\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmnist_training_pipeline\u001b[39m():\n\u001b[0;32m     60\u001b[0m \n\u001b[0;32m     61\u001b[0m     \u001b[38;5;66;03m# Step 1: Create the dataframe\u001b[39;00m\n\u001b[0;32m     62\u001b[0m     df \u001b[38;5;241m=\u001b[39m create_dataframe()\n\u001b[0;32m     64\u001b[0m     \u001b[38;5;66;03m# Step 2: Split the dataframe\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\Lib\\site-packages\\kfp\\dsl\\pipeline_context.py:65\u001b[0m, in \u001b[0;36mpipeline\u001b[1;34m(func, name, description, pipeline_root, display_name)\u001b[0m\n\u001b[0;32m     62\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m pipeline_root:\n\u001b[0;32m     63\u001b[0m     func\u001b[38;5;241m.\u001b[39mpipeline_root \u001b[38;5;241m=\u001b[39m pipeline_root\n\u001b[1;32m---> 65\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m component_factory\u001b[38;5;241m.\u001b[39mcreate_graph_component_from_func(\n\u001b[0;32m     66\u001b[0m     func,\n\u001b[0;32m     67\u001b[0m     name\u001b[38;5;241m=\u001b[39mname,\n\u001b[0;32m     68\u001b[0m     description\u001b[38;5;241m=\u001b[39mdescription,\n\u001b[0;32m     69\u001b[0m     display_name\u001b[38;5;241m=\u001b[39mdisplay_name,\n\u001b[0;32m     70\u001b[0m )\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\Lib\\site-packages\\kfp\\dsl\\component_factory.py:636\u001b[0m, in \u001b[0;36mcreate_graph_component_from_func\u001b[1;34m(func, name, description, display_name)\u001b[0m\n\u001b[0;32m    625\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Implementation for the @pipeline decorator.\u001b[39;00m\n\u001b[0;32m    626\u001b[0m \n\u001b[0;32m    627\u001b[0m \u001b[38;5;124;03mThe decorator is defined under pipeline_context.py. See the\u001b[39;00m\n\u001b[0;32m    628\u001b[0m \u001b[38;5;124;03mdecorator for the canonical documentation for this function.\u001b[39;00m\n\u001b[0;32m    629\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    631\u001b[0m component_spec \u001b[38;5;241m=\u001b[39m extract_component_interface(\n\u001b[0;32m    632\u001b[0m     func,\n\u001b[0;32m    633\u001b[0m     description\u001b[38;5;241m=\u001b[39mdescription,\n\u001b[0;32m    634\u001b[0m     name\u001b[38;5;241m=\u001b[39mname,\n\u001b[0;32m    635\u001b[0m )\n\u001b[1;32m--> 636\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m graph_component\u001b[38;5;241m.\u001b[39mGraphComponent(\n\u001b[0;32m    637\u001b[0m     component_spec\u001b[38;5;241m=\u001b[39mcomponent_spec,\n\u001b[0;32m    638\u001b[0m     pipeline_func\u001b[38;5;241m=\u001b[39mfunc,\n\u001b[0;32m    639\u001b[0m     display_name\u001b[38;5;241m=\u001b[39mdisplay_name,\n\u001b[0;32m    640\u001b[0m )\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\Lib\\site-packages\\kfp\\dsl\\graph_component.py:58\u001b[0m, in \u001b[0;36mGraphComponent.__init__\u001b[1;34m(self, component_spec, pipeline_func, display_name)\u001b[0m\n\u001b[0;32m     49\u001b[0m     args_list\u001b[38;5;241m.\u001b[39mappend(\n\u001b[0;32m     50\u001b[0m         pipeline_channel\u001b[38;5;241m.\u001b[39mcreate_pipeline_channel(\n\u001b[0;32m     51\u001b[0m             name\u001b[38;5;241m=\u001b[39marg_name,\n\u001b[0;32m     52\u001b[0m             channel_type\u001b[38;5;241m=\u001b[39minput_spec\u001b[38;5;241m.\u001b[39mtype,\n\u001b[0;32m     53\u001b[0m             is_artifact_list\u001b[38;5;241m=\u001b[39minput_spec\u001b[38;5;241m.\u001b[39mis_artifact_list,\n\u001b[0;32m     54\u001b[0m         ))\n\u001b[0;32m     56\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m pipeline_context\u001b[38;5;241m.\u001b[39mPipeline(\n\u001b[0;32m     57\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcomponent_spec\u001b[38;5;241m.\u001b[39mname) \u001b[38;5;28;01mas\u001b[39;00m dsl_pipeline:\n\u001b[1;32m---> 58\u001b[0m     pipeline_outputs \u001b[38;5;241m=\u001b[39m pipeline_func(\u001b[38;5;241m*\u001b[39margs_list)\n\u001b[0;32m     60\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m dsl_pipeline\u001b[38;5;241m.\u001b[39mtasks:\n\u001b[0;32m     61\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTask is missing from pipeline.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "Cell \u001b[1;32mIn[2], line 76\u001b[0m, in \u001b[0;36mmnist_training_pipeline\u001b[1;34m()\u001b[0m\n\u001b[0;32m     73\u001b[0m \u001b[38;5;66;03m# Step 5: Evaluate the model\u001b[39;00m\n\u001b[0;32m     74\u001b[0m evaluate_model(model, test_df)\n\u001b[1;32m---> 76\u001b[0m deployment_manifest \u001b[38;5;241m=\u001b[39m deploy_model(model)\n\u001b[0;32m     77\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDeployment Manifest:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mdeployment_manifest\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[2], line 42\u001b[0m, in \u001b[0;36mdeploy_model\u001b[1;34m(model)\u001b[0m\n\u001b[0;32m     40\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdeploy_model\u001b[39m(model):\n\u001b[0;32m     41\u001b[0m     \u001b[38;5;66;03m# Create a Kubernetes deployment\u001b[39;00m\n\u001b[1;32m---> 42\u001b[0m     deployment \u001b[38;5;241m=\u001b[39m kfp\u001b[38;5;241m.\u001b[39mcomponents\u001b[38;5;241m.\u001b[39mcreate_deployment(\n\u001b[0;32m     43\u001b[0m         name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmnist-model\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m     44\u001b[0m         image\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgcr.io/my-project/mnist-model:latest\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m     45\u001b[0m         replicas\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[0;32m     46\u001b[0m     )\n\u001b[0;32m     48\u001b[0m     \u001b[38;5;66;03m# Create a Kubernetes service\u001b[39;00m\n\u001b[0;32m     49\u001b[0m     service \u001b[38;5;241m=\u001b[39m kfp\u001b[38;5;241m.\u001b[39mcomponents\u001b[38;5;241m.\u001b[39mcreate_service(\n\u001b[0;32m     50\u001b[0m         name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmnist-model\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m     51\u001b[0m         selector\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mapp=mnist-model\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m     52\u001b[0m     )\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'kfp.components' has no attribute 'create_deployment'"
     ]
    }
   ],
   "source": [
    "import kfp\n",
    "from kfp import components\n",
    "from kfp.dsl import pipeline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Create a random dataframe\n",
    "def create_dataframe():\n",
    "    df = pd.DataFrame({'x': np.random.rand(100), 'y': np.random.rand(100)})\n",
    "    return df\n",
    "\n",
    "# Split the dataframe into a training set and a test set\n",
    "def split_dataframe(df):\n",
    "    train_df, test_df = train_test_split(df, test_size=0.2)\n",
    "    return train_df, test_df\n",
    "\n",
    "# Scale the features in the training set\n",
    "def scale_features(train_df):\n",
    "    scaler = StandardScaler()\n",
    "    scaled_x = scaler.fit_transform(train_df[['x']])\n",
    "    return pd.DataFrame(data={'x': scaled_x[:, 0], 'y': train_df['y']})\n",
    "\n",
    "# Train a machine learning model on the training set\n",
    "def train_model(train_df):\n",
    "    model = LinearRegression()\n",
    "    model.fit(train_df[['x']], train_df['y'])\n",
    "    return model\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "def evaluate_model(model, test_df):\n",
    "    preds = model.predict(test_df[['x']])\n",
    "    rmse = np.sqrt(mean_squared_error(test_df['y'], preds))\n",
    "    print('RMSE: {}'.format(rmse))\n",
    "\n",
    "# Deploy the model to production\n",
    "def deploy_model(model):\n",
    "    # Create a Kubernetes deployment\n",
    "    deployment = kfp.components.create_deployment(\n",
    "        name='mnist-model',\n",
    "        image='gcr.io/my-project/mnist-model:latest',\n",
    "        replicas=1\n",
    "    )\n",
    "\n",
    "    # Create a Kubernetes service\n",
    "    service = kfp.components.create_service(\n",
    "        name='mnist-model',\n",
    "        selector='app=mnist-model'\n",
    "    )\n",
    "\n",
    "    # Return the deployment and service objects\n",
    "    return deployment, service\n",
    "\n",
    "# Create a pipeline\n",
    "@pipeline(name='MNIST training pipeline')\n",
    "def mnist_training_pipeline():\n",
    "\n",
    "    # Step 1: Create the dataframe\n",
    "    df = create_dataframe()\n",
    "\n",
    "    # Step 2: Split the dataframe\n",
    "    train_df, test_df = split_dataframe(df)\n",
    "\n",
    "    # Step 3: Scale the features\n",
    "    scaled_train_df = scale_features(train_df)\n",
    "\n",
    "    # Step 4: Train the model\n",
    "    model = train_model(scaled_train_df)\n",
    "\n",
    "    # Step 5: Evaluate the model\n",
    "    evaluate_model(model, test_df)\n",
    "\n",
    "    deployment_manifest = deploy_model(model)\n",
    "    print(f\"Deployment Manifest:\\n{deployment_manifest}\")\n",
    "\n",
    "# Run the pipeline\n",
    "if __name__ == '__main__':\n",
    "    kfp.compiler.Compiler().compile(mnist_training_pipeline, 'mnist_training_pipeline.yaml')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ad7567b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.31769074305059936\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "module 'kfp.dsl' has no attribute 'ResourceOp'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 11\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m mean_squared_error\n\u001b[0;32m     10\u001b[0m \u001b[38;5;66;03m# Define a Kubeflow pipeline\u001b[39;00m\n\u001b[1;32m---> 11\u001b[0m \u001b[38;5;129m@pipeline\u001b[39m(name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMNIST training pipeline\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmnist_training_pipeline\u001b[39m():\n\u001b[0;32m     13\u001b[0m \n\u001b[0;32m     14\u001b[0m     \u001b[38;5;66;03m# Step 1: Create a random dataframe\u001b[39;00m\n\u001b[0;32m     15\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcreate_dataframe\u001b[39m():\n\u001b[0;32m     16\u001b[0m         df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame({\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mx\u001b[39m\u001b[38;5;124m'\u001b[39m: np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mrand(\u001b[38;5;241m100\u001b[39m), \u001b[38;5;124m'\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m'\u001b[39m: np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mrand(\u001b[38;5;241m100\u001b[39m)})\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\Lib\\site-packages\\kfp\\dsl\\pipeline_context.py:65\u001b[0m, in \u001b[0;36mpipeline\u001b[1;34m(func, name, description, pipeline_root, display_name)\u001b[0m\n\u001b[0;32m     62\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m pipeline_root:\n\u001b[0;32m     63\u001b[0m     func\u001b[38;5;241m.\u001b[39mpipeline_root \u001b[38;5;241m=\u001b[39m pipeline_root\n\u001b[1;32m---> 65\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m component_factory\u001b[38;5;241m.\u001b[39mcreate_graph_component_from_func(\n\u001b[0;32m     66\u001b[0m     func,\n\u001b[0;32m     67\u001b[0m     name\u001b[38;5;241m=\u001b[39mname,\n\u001b[0;32m     68\u001b[0m     description\u001b[38;5;241m=\u001b[39mdescription,\n\u001b[0;32m     69\u001b[0m     display_name\u001b[38;5;241m=\u001b[39mdisplay_name,\n\u001b[0;32m     70\u001b[0m )\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\Lib\\site-packages\\kfp\\dsl\\component_factory.py:636\u001b[0m, in \u001b[0;36mcreate_graph_component_from_func\u001b[1;34m(func, name, description, display_name)\u001b[0m\n\u001b[0;32m    625\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Implementation for the @pipeline decorator.\u001b[39;00m\n\u001b[0;32m    626\u001b[0m \n\u001b[0;32m    627\u001b[0m \u001b[38;5;124;03mThe decorator is defined under pipeline_context.py. See the\u001b[39;00m\n\u001b[0;32m    628\u001b[0m \u001b[38;5;124;03mdecorator for the canonical documentation for this function.\u001b[39;00m\n\u001b[0;32m    629\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    631\u001b[0m component_spec \u001b[38;5;241m=\u001b[39m extract_component_interface(\n\u001b[0;32m    632\u001b[0m     func,\n\u001b[0;32m    633\u001b[0m     description\u001b[38;5;241m=\u001b[39mdescription,\n\u001b[0;32m    634\u001b[0m     name\u001b[38;5;241m=\u001b[39mname,\n\u001b[0;32m    635\u001b[0m )\n\u001b[1;32m--> 636\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m graph_component\u001b[38;5;241m.\u001b[39mGraphComponent(\n\u001b[0;32m    637\u001b[0m     component_spec\u001b[38;5;241m=\u001b[39mcomponent_spec,\n\u001b[0;32m    638\u001b[0m     pipeline_func\u001b[38;5;241m=\u001b[39mfunc,\n\u001b[0;32m    639\u001b[0m     display_name\u001b[38;5;241m=\u001b[39mdisplay_name,\n\u001b[0;32m    640\u001b[0m )\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\Lib\\site-packages\\kfp\\dsl\\graph_component.py:58\u001b[0m, in \u001b[0;36mGraphComponent.__init__\u001b[1;34m(self, component_spec, pipeline_func, display_name)\u001b[0m\n\u001b[0;32m     49\u001b[0m     args_list\u001b[38;5;241m.\u001b[39mappend(\n\u001b[0;32m     50\u001b[0m         pipeline_channel\u001b[38;5;241m.\u001b[39mcreate_pipeline_channel(\n\u001b[0;32m     51\u001b[0m             name\u001b[38;5;241m=\u001b[39marg_name,\n\u001b[0;32m     52\u001b[0m             channel_type\u001b[38;5;241m=\u001b[39minput_spec\u001b[38;5;241m.\u001b[39mtype,\n\u001b[0;32m     53\u001b[0m             is_artifact_list\u001b[38;5;241m=\u001b[39minput_spec\u001b[38;5;241m.\u001b[39mis_artifact_list,\n\u001b[0;32m     54\u001b[0m         ))\n\u001b[0;32m     56\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m pipeline_context\u001b[38;5;241m.\u001b[39mPipeline(\n\u001b[0;32m     57\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcomponent_spec\u001b[38;5;241m.\u001b[39mname) \u001b[38;5;28;01mas\u001b[39;00m dsl_pipeline:\n\u001b[1;32m---> 58\u001b[0m     pipeline_outputs \u001b[38;5;241m=\u001b[39m pipeline_func(\u001b[38;5;241m*\u001b[39margs_list)\n\u001b[0;32m     60\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m dsl_pipeline\u001b[38;5;241m.\u001b[39mtasks:\n\u001b[0;32m     61\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTask is missing from pipeline.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "Cell \u001b[1;32mIn[3], line 98\u001b[0m, in \u001b[0;36mmnist_training_pipeline\u001b[1;34m()\u001b[0m\n\u001b[0;32m     96\u001b[0m model \u001b[38;5;241m=\u001b[39m train_model(scaled_train_df)\n\u001b[0;32m     97\u001b[0m evaluate_model(model, test_df)\n\u001b[1;32m---> 98\u001b[0m deploy_op \u001b[38;5;241m=\u001b[39m deploy_model(model)\n\u001b[0;32m     99\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDeployment Op: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdeploy_op\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[3], line 77\u001b[0m, in \u001b[0;36mmnist_training_pipeline.<locals>.deploy_model\u001b[1;34m(model)\u001b[0m\n\u001b[0;32m     45\u001b[0m deployment_resource \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m     46\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mapiVersion\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mapps/v1\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     47\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mkind\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDeployment\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     73\u001b[0m     },\n\u001b[0;32m     74\u001b[0m }\n\u001b[0;32m     76\u001b[0m \u001b[38;5;66;03m# Create a Kubernetes deployment resource using k8s.dsl.ResourceOp\u001b[39;00m\n\u001b[1;32m---> 77\u001b[0m deployment_op \u001b[38;5;241m=\u001b[39m kfp\u001b[38;5;241m.\u001b[39mdsl\u001b[38;5;241m.\u001b[39mResourceOp(\n\u001b[0;32m     78\u001b[0m     name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcreate-deployment\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     79\u001b[0m     k8s_resource\u001b[38;5;241m=\u001b[39mdeployment_resource,\n\u001b[0;32m     80\u001b[0m     action\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mapply\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     81\u001b[0m )\n\u001b[0;32m     83\u001b[0m \u001b[38;5;66;03m# Apply the deployment using kubectl\u001b[39;00m\n\u001b[0;32m     84\u001b[0m kfp\u001b[38;5;241m.\u001b[39mdsl\u001b[38;5;241m.\u001b[39mContainerOp(\n\u001b[0;32m     85\u001b[0m     name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mapply-k8s-deployment\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     86\u001b[0m     image\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlachlanevenson/k8s-kubectl:v1.18.8\u001b[39m\u001b[38;5;124m\"\u001b[39m,  \u001b[38;5;66;03m# Replace with an appropriate kubectl image\u001b[39;00m\n\u001b[0;32m     87\u001b[0m     command\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mkubectl\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mapply\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m-f\u001b[39m\u001b[38;5;124m\"\u001b[39m, deployment_op\u001b[38;5;241m.\u001b[39moutputs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresourceReferences\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;241m0\u001b[39m]],\n\u001b[0;32m     88\u001b[0m )\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'kfp.dsl' has no attribute 'ResourceOp'"
     ]
    }
   ],
   "source": [
    "import kfp\n",
    "from kfp.dsl import pipeline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Define a Kubeflow pipeline\n",
    "@pipeline(name='MNIST training pipeline')\n",
    "def mnist_training_pipeline():\n",
    "\n",
    "    # Step 1: Create a random dataframe\n",
    "    def create_dataframe():\n",
    "        df = pd.DataFrame({'x': np.random.rand(100), 'y': np.random.rand(100)})\n",
    "        return df\n",
    "    \n",
    "    # Step 2: Split the dataframe into a training set and a test set\n",
    "    def split_dataframe(df):\n",
    "        train_df, test_df = train_test_split(df, test_size=0.2)\n",
    "        return train_df, test_df\n",
    "    \n",
    "    # Step 3: Scale the features in the training set\n",
    "    def scale_features(train_df):\n",
    "        scaler = StandardScaler()\n",
    "        scaled_x = scaler.fit_transform(train_df[['x']])\n",
    "        return pd.DataFrame(data={'x': scaled_x[:, 0], 'y': train_df['y']})\n",
    "    \n",
    "    # Step 4: Train a machine learning model on the training set\n",
    "    def train_model(train_df):\n",
    "        model = LinearRegression()\n",
    "        model.fit(train_df[['x']], train_df['y'])\n",
    "        return model\n",
    "    \n",
    "    # Step 5: Evaluate the model on the test set\n",
    "    def evaluate_model(model, test_df):\n",
    "        preds = model.predict(test_df[['x']])\n",
    "        rmse = np.sqrt(mean_squared_error(test_df['y'], preds))\n",
    "        print('RMSE: {}'.format(rmse))\n",
    "    \n",
    "    # Step 6: Deploy the model to production\n",
    "    def deploy_model(model):\n",
    "        # Define a Kubernetes deployment resource\n",
    "        deployment_resource = {\n",
    "            \"apiVersion\": \"apps/v1\",\n",
    "            \"kind\": \"Deployment\",\n",
    "            \"metadata\": {\n",
    "                \"name\": \"mnist-model\",\n",
    "            },\n",
    "            \"spec\": {\n",
    "                \"replicas\": 1,\n",
    "                \"selector\": {\n",
    "                    \"matchLabels\": {\n",
    "                        \"app\": \"mnist-model\",\n",
    "                    },\n",
    "                },\n",
    "                \"template\": {\n",
    "                    \"metadata\": {\n",
    "                        \"labels\": {\n",
    "                            \"app\": \"mnist-model\",\n",
    "                        },\n",
    "                    },\n",
    "                    \"spec\": {\n",
    "                        \"containers\": [\n",
    "                            {\n",
    "                                \"name\": \"mnist-model\",\n",
    "                                \"image\": \"gcr.io/my-project/mnist-model:latest\",  # Replace with your image\n",
    "                            },\n",
    "                        ],\n",
    "                    },\n",
    "                },\n",
    "            },\n",
    "        }\n",
    "\n",
    "        # Create a Kubernetes deployment resource using k8s.dsl.ResourceOp\n",
    "        deployment_op = kfp.dsl.ResourceOp(\n",
    "            name=\"create-deployment\",\n",
    "            k8s_resource=deployment_resource,\n",
    "            action=\"apply\",\n",
    "        )\n",
    "\n",
    "        # Apply the deployment using kubectl\n",
    "        kfp.dsl.ContainerOp(\n",
    "            name=\"apply-k8s-deployment\",\n",
    "            image=\"lachlanevenson/k8s-kubectl:v1.18.8\",  # Replace with an appropriate kubectl image\n",
    "            command=[\"kubectl\", \"apply\", \"-f\", deployment_op.outputs[\"resourceReferences\"][0]],\n",
    "        )\n",
    "\n",
    "        return deployment_op\n",
    "\n",
    "    # Step 7: Create the pipeline steps\n",
    "    df = create_dataframe()\n",
    "    train_df, test_df = split_dataframe(df)\n",
    "    scaled_train_df = scale_features(train_df)\n",
    "    model = train_model(scaled_train_df)\n",
    "    evaluate_model(model, test_df)\n",
    "    deploy_op = deploy_model(model)\n",
    "    print(f\"Deployment Op: {deploy_op}\")\n",
    "\n",
    "# Run the pipeline\n",
    "if __name__ == '__main__':\n",
    "    kfp.compiler.Compiler().compile(mnist_training_pipeline, 'mnist_training_pipeline.yaml')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7d6afd51",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (1959590225.py, line 71)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[4], line 71\u001b[1;36m\u001b[0m\n\u001b[1;33m    .after(create_dataframe)  # Define the dependency on the previous step\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "import kfp\n",
    "from kfp.dsl import pipeline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Define a Kubeflow pipeline\n",
    "@pipeline(name='MNIST training pipeline')\n",
    "def mnist_training_pipeline():\n",
    "\n",
    "    # Step 1: Create a random dataframe\n",
    "    def create_dataframe():\n",
    "        df = pd.DataFrame({'x': np.random.rand(100), 'y': np.random.rand(100)})\n",
    "        return df\n",
    "    \n",
    "    # Step 2: Split the dataframe into a training set and a test set\n",
    "    def split_dataframe(df):\n",
    "        train_df, test_df = train_test_split(df, test_size=0.2)\n",
    "        return train_df, test_df\n",
    "    \n",
    "    # Step 3: Scale the features in the training set\n",
    "    def scale_features(train_df):\n",
    "        scaler = StandardScaler()\n",
    "        scaled_x = scaler.fit_transform(train_df[['x']])\n",
    "        return pd.DataFrame(data={'x': scaled_x[:, 0], 'y': train_df['y']})\n",
    "    \n",
    "    # Step 4: Train a machine learning model on the training set\n",
    "    def train_model(train_df):\n",
    "        model = LinearRegression()\n",
    "        model.fit(train_df[['x']], train_df['y'])\n",
    "        return model\n",
    "    \n",
    "    # Step 5: Evaluate the model on the test set\n",
    "    def evaluate_model(model, test_df):\n",
    "        preds = model.predict(test_df[['x']])\n",
    "        rmse = np.sqrt(mean_squared_error(test_df['y'], preds))\n",
    "        print('RMSE: {}'.format(rmse))\n",
    "    \n",
    "    # Step 6: Deploy the model to production\n",
    "    def deploy_model(model):\n",
    "        # Define a Kubernetes deployment resource as a YAML string\n",
    "        deployment_yaml = f\"\"\"\n",
    "        apiVersion: apps/v1\n",
    "        kind: Deployment\n",
    "        metadata:\n",
    "          name: mnist-model\n",
    "        spec:\n",
    "          replicas: 1\n",
    "          selector:\n",
    "            matchLabels:\n",
    "              app: mnist-model\n",
    "          template:\n",
    "            metadata:\n",
    "              labels:\n",
    "                app: mnist-model\n",
    "            spec:\n",
    "              containers:\n",
    "                - name: mnist-model\n",
    "                  image: gcr.io/my-project/mnist-model:latest  # Replace with your image\n",
    "        \"\"\"\n",
    "        \n",
    "        # Apply the Kubernetes deployment using kubectl\n",
    "        kfp.dsl.ContainerOp(\n",
    "            name=\"apply-k8s-deployment\",\n",
    "            image=\"lachlanevenson/k8s-kubectl:v1.18.8\",  # Replace with an appropriate kubectl image\n",
    "            command=[\"kubectl\", \"apply\", \"-f\", \"-\"],\n",
    "        ).add_pvolumes({\"/mnt\": kfp.dsl.PipelineVolume(pvc=\"my-pvc\")})  # Replace with your PVC if needed\n",
    "        .after(create_dataframe)  # Define the dependency on the previous step\n",
    "    \n",
    "    # Step 7: Create the pipeline steps\n",
    "    df = create_dataframe()\n",
    "    train_df, test_df = split_dataframe(df)\n",
    "    scaled_train_df = scale_features(train_df)\n",
    "    model = train_model(scaled_train_df)\n",
    "    evaluate_model(model, test_df)\n",
    "    deploy_model(model)\n",
    "    \n",
    "# Run the pipeline\n",
    "if __name__ == '__main__':\n",
    "    kfp.compiler.Compiler().compile(mnist_training_pipeline, 'mnist_training_pipeline.yaml')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2c39378a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.2959324781073562\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "module 'kfp.dsl' has no attribute 'ContainerOp'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 11\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m mean_squared_error\n\u001b[0;32m     10\u001b[0m \u001b[38;5;66;03m# Define a Kubeflow pipeline\u001b[39;00m\n\u001b[1;32m---> 11\u001b[0m \u001b[38;5;129m@pipeline\u001b[39m(name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMNIST training pipeline\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmnist_training_pipeline\u001b[39m():\n\u001b[0;32m     13\u001b[0m \n\u001b[0;32m     14\u001b[0m     \u001b[38;5;66;03m# Step 1: Create a random dataframe\u001b[39;00m\n\u001b[0;32m     15\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcreate_dataframe\u001b[39m():\n\u001b[0;32m     16\u001b[0m         df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame({\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mx\u001b[39m\u001b[38;5;124m'\u001b[39m: np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mrand(\u001b[38;5;241m100\u001b[39m), \u001b[38;5;124m'\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m'\u001b[39m: np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mrand(\u001b[38;5;241m100\u001b[39m)})\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\Lib\\site-packages\\kfp\\dsl\\pipeline_context.py:65\u001b[0m, in \u001b[0;36mpipeline\u001b[1;34m(func, name, description, pipeline_root, display_name)\u001b[0m\n\u001b[0;32m     62\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m pipeline_root:\n\u001b[0;32m     63\u001b[0m     func\u001b[38;5;241m.\u001b[39mpipeline_root \u001b[38;5;241m=\u001b[39m pipeline_root\n\u001b[1;32m---> 65\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m component_factory\u001b[38;5;241m.\u001b[39mcreate_graph_component_from_func(\n\u001b[0;32m     66\u001b[0m     func,\n\u001b[0;32m     67\u001b[0m     name\u001b[38;5;241m=\u001b[39mname,\n\u001b[0;32m     68\u001b[0m     description\u001b[38;5;241m=\u001b[39mdescription,\n\u001b[0;32m     69\u001b[0m     display_name\u001b[38;5;241m=\u001b[39mdisplay_name,\n\u001b[0;32m     70\u001b[0m )\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\Lib\\site-packages\\kfp\\dsl\\component_factory.py:636\u001b[0m, in \u001b[0;36mcreate_graph_component_from_func\u001b[1;34m(func, name, description, display_name)\u001b[0m\n\u001b[0;32m    625\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Implementation for the @pipeline decorator.\u001b[39;00m\n\u001b[0;32m    626\u001b[0m \n\u001b[0;32m    627\u001b[0m \u001b[38;5;124;03mThe decorator is defined under pipeline_context.py. See the\u001b[39;00m\n\u001b[0;32m    628\u001b[0m \u001b[38;5;124;03mdecorator for the canonical documentation for this function.\u001b[39;00m\n\u001b[0;32m    629\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    631\u001b[0m component_spec \u001b[38;5;241m=\u001b[39m extract_component_interface(\n\u001b[0;32m    632\u001b[0m     func,\n\u001b[0;32m    633\u001b[0m     description\u001b[38;5;241m=\u001b[39mdescription,\n\u001b[0;32m    634\u001b[0m     name\u001b[38;5;241m=\u001b[39mname,\n\u001b[0;32m    635\u001b[0m )\n\u001b[1;32m--> 636\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m graph_component\u001b[38;5;241m.\u001b[39mGraphComponent(\n\u001b[0;32m    637\u001b[0m     component_spec\u001b[38;5;241m=\u001b[39mcomponent_spec,\n\u001b[0;32m    638\u001b[0m     pipeline_func\u001b[38;5;241m=\u001b[39mfunc,\n\u001b[0;32m    639\u001b[0m     display_name\u001b[38;5;241m=\u001b[39mdisplay_name,\n\u001b[0;32m    640\u001b[0m )\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\Lib\\site-packages\\kfp\\dsl\\graph_component.py:58\u001b[0m, in \u001b[0;36mGraphComponent.__init__\u001b[1;34m(self, component_spec, pipeline_func, display_name)\u001b[0m\n\u001b[0;32m     49\u001b[0m     args_list\u001b[38;5;241m.\u001b[39mappend(\n\u001b[0;32m     50\u001b[0m         pipeline_channel\u001b[38;5;241m.\u001b[39mcreate_pipeline_channel(\n\u001b[0;32m     51\u001b[0m             name\u001b[38;5;241m=\u001b[39marg_name,\n\u001b[0;32m     52\u001b[0m             channel_type\u001b[38;5;241m=\u001b[39minput_spec\u001b[38;5;241m.\u001b[39mtype,\n\u001b[0;32m     53\u001b[0m             is_artifact_list\u001b[38;5;241m=\u001b[39minput_spec\u001b[38;5;241m.\u001b[39mis_artifact_list,\n\u001b[0;32m     54\u001b[0m         ))\n\u001b[0;32m     56\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m pipeline_context\u001b[38;5;241m.\u001b[39mPipeline(\n\u001b[0;32m     57\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcomponent_spec\u001b[38;5;241m.\u001b[39mname) \u001b[38;5;28;01mas\u001b[39;00m dsl_pipeline:\n\u001b[1;32m---> 58\u001b[0m     pipeline_outputs \u001b[38;5;241m=\u001b[39m pipeline_func(\u001b[38;5;241m*\u001b[39margs_list)\n\u001b[0;32m     60\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m dsl_pipeline\u001b[38;5;241m.\u001b[39mtasks:\n\u001b[0;32m     61\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTask is missing from pipeline.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "Cell \u001b[1;32mIn[5], line 81\u001b[0m, in \u001b[0;36mmnist_training_pipeline\u001b[1;34m()\u001b[0m\n\u001b[0;32m     78\u001b[0m evaluate_model(model, test_df)\n\u001b[0;32m     80\u001b[0m \u001b[38;5;66;03m# Step 8: Deploy the model (make sure it's the last step)\u001b[39;00m\n\u001b[1;32m---> 81\u001b[0m deploy_op \u001b[38;5;241m=\u001b[39m deploy_model(model)\n",
      "Cell \u001b[1;32mIn[5], line 66\u001b[0m, in \u001b[0;36mmnist_training_pipeline.<locals>.deploy_model\u001b[1;34m(model)\u001b[0m\n\u001b[0;32m     45\u001b[0m deployment_yaml \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[0;32m     46\u001b[0m \u001b[38;5;124mapiVersion: apps/v1\u001b[39m\n\u001b[0;32m     47\u001b[0m \u001b[38;5;124mkind: Deployment\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     62\u001b[0m \u001b[38;5;124m          image: gcr.io/my-project/mnist-model:latest  # Replace with your image\u001b[39m\n\u001b[0;32m     63\u001b[0m \u001b[38;5;124m\u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[0;32m     65\u001b[0m \u001b[38;5;66;03m# Apply the Kubernetes deployment using kubectl\u001b[39;00m\n\u001b[1;32m---> 66\u001b[0m kfp\u001b[38;5;241m.\u001b[39mdsl\u001b[38;5;241m.\u001b[39mContainerOp(\n\u001b[0;32m     67\u001b[0m     name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mapply-k8s-deployment\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     68\u001b[0m     image\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlachlanevenson/k8s-kubectl:v1.18.8\u001b[39m\u001b[38;5;124m\"\u001b[39m,  \u001b[38;5;66;03m# Replace with an appropriate kubectl image\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     command\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mkubectl\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mapply\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m-f\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m-\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m     70\u001b[0m     file_outputs\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdeployment_yaml\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/mnt/deployment.yaml\u001b[39m\u001b[38;5;124m\"\u001b[39m},  \u001b[38;5;66;03m# Output the deployment YAML\u001b[39;00m\n\u001b[0;32m     71\u001b[0m )\u001b[38;5;241m.\u001b[39madd_pvolumes({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/mnt\u001b[39m\u001b[38;5;124m\"\u001b[39m: kfp\u001b[38;5;241m.\u001b[39mdsl\u001b[38;5;241m.\u001b[39mPipelineVolume(pvc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmy-pvc\u001b[39m\u001b[38;5;124m\"\u001b[39m)})\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'kfp.dsl' has no attribute 'ContainerOp'"
     ]
    }
   ],
   "source": [
    "import kfp\n",
    "from kfp.dsl import pipeline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Define a Kubeflow pipeline\n",
    "@pipeline(name='MNIST training pipeline')\n",
    "def mnist_training_pipeline():\n",
    "\n",
    "    # Step 1: Create a random dataframe\n",
    "    def create_dataframe():\n",
    "        df = pd.DataFrame({'x': np.random.rand(100), 'y': np.random.rand(100)})\n",
    "        return df\n",
    "    \n",
    "    # Step 2: Split the dataframe into a training set and a test set\n",
    "    def split_dataframe(df):\n",
    "        train_df, test_df = train_test_split(df, test_size=0.2)\n",
    "        return train_df, test_df\n",
    "    \n",
    "    # Step 3: Scale the features in the training set\n",
    "    def scale_features(train_df):\n",
    "        scaler = StandardScaler()\n",
    "        scaled_x = scaler.fit_transform(train_df[['x']])\n",
    "        return pd.DataFrame(data={'x': scaled_x[:, 0], 'y': train_df['y']})\n",
    "    \n",
    "    # Step 4: Train a machine learning model on the training set\n",
    "    def train_model(train_df):\n",
    "        model = LinearRegression()\n",
    "        model.fit(train_df[['x']], train_df['y'])\n",
    "        return model\n",
    "    \n",
    "    # Step 5: Evaluate the model on the test set\n",
    "    def evaluate_model(model, test_df):\n",
    "        preds = model.predict(test_df[['x']])\n",
    "        rmse = np.sqrt(mean_squared_error(test_df['y'], preds))\n",
    "        print('RMSE: {}'.format(rmse))\n",
    "    \n",
    "    # Step 6: Deploy the model to production\n",
    "    def deploy_model(model):\n",
    "        # Define a Kubernetes deployment resource as a YAML string\n",
    "        deployment_yaml = f\"\"\"\n",
    "        apiVersion: apps/v1\n",
    "        kind: Deployment\n",
    "        metadata:\n",
    "          name: mnist-model\n",
    "        spec:\n",
    "          replicas: 1\n",
    "          selector:\n",
    "            matchLabels:\n",
    "              app: mnist-model\n",
    "          template:\n",
    "            metadata:\n",
    "              labels:\n",
    "                app: mnist-model\n",
    "            spec:\n",
    "              containers:\n",
    "                - name: mnist-model\n",
    "                  image: gcr.io/my-project/mnist-model:latest  # Replace with your image\n",
    "        \"\"\"\n",
    "        \n",
    "        # Apply the Kubernetes deployment using kubectl\n",
    "        kfp.dsl.ContainerOp(\n",
    "            name=\"apply-k8s-deployment\",\n",
    "            image=\"lachlanevenson/k8s-kubectl:v1.18.8\",  # Replace with an appropriate kubectl image\n",
    "            command=[\"kubectl\", \"apply\", \"-f\", \"-\"],\n",
    "            file_outputs={\"deployment_yaml\": \"/mnt/deployment.yaml\"},  # Output the deployment YAML\n",
    "        ).add_pvolumes({\"/mnt\": kfp.dsl.PipelineVolume(pvc=\"my-pvc\")})  # Replace with your PVC if needed\n",
    "    \n",
    "    # Step 7: Create the pipeline steps\n",
    "    df = create_dataframe()\n",
    "    train_df, test_df = split_dataframe(df)\n",
    "    scaled_train_df = scale_features(train_df)\n",
    "    model = train_model(scaled_train_df)\n",
    "    evaluate_model(model, test_df)\n",
    "    \n",
    "    # Step 8: Deploy the model (make sure it's the last step)\n",
    "    deploy_op = deploy_model(model)\n",
    "    \n",
    "# Run the pipeline\n",
    "if __name__ == '__main__':\n",
    "    kfp.compiler.Compiler().compile(mnist_training_pipeline, 'mnist_training_pipeline.yaml')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a6046d0e",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'ContainerOp' from 'kfp.dsl' (C:\\Users\\pcx\\AppData\\Local\\anaconda3\\Lib\\site-packages\\kfp\\dsl\\__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mkfp\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkfp\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdsl\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m pipeline, ContainerOp\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'ContainerOp' from 'kfp.dsl' (C:\\Users\\pcx\\AppData\\Local\\anaconda3\\Lib\\site-packages\\kfp\\dsl\\__init__.py)"
     ]
    }
   ],
   "source": [
    "import kfp\n",
    "from kfp.dsl import pipeline, ContainerOp\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Define a Kubeflow pipeline\n",
    "@pipeline(name='MNIST training pipeline')\n",
    "def mnist_training_pipeline():\n",
    "\n",
    "    # Step 1: Create a random dataframe\n",
    "    def create_dataframe():\n",
    "        df = pd.DataFrame({'x': np.random.rand(100), 'y': np.random.rand(100)})\n",
    "        return df\n",
    "    \n",
    "    # Step 2: Split the dataframe into a training set and a test set\n",
    "    def split_dataframe(df):\n",
    "        train_df, test_df = train_test_split(df, test_size=0.2)\n",
    "        return train_df, test_df\n",
    "    \n",
    "    # Step 3: Scale the features in the training set\n",
    "    def scale_features(train_df):\n",
    "        scaler = StandardScaler()\n",
    "        scaled_x = scaler.fit_transform(train_df[['x']])\n",
    "        return pd.DataFrame(data={'x': scaled_x[:, 0], 'y': train_df['y']})\n",
    "    \n",
    "    # Step 4: Train a machine learning model on the training set\n",
    "    def train_model(train_df):\n",
    "        model = LinearRegression()\n",
    "        model.fit(train_df[['x']], train_df['y'])\n",
    "        return model\n",
    "    \n",
    "    # Step 5: Evaluate the model on the test set\n",
    "    def evaluate_model(model, test_df):\n",
    "        preds = model.predict(test_df[['x']])\n",
    "        rmse = np.sqrt(mean_squared_error(test_df['y'], preds))\n",
    "        print('RMSE: {}'.format(rmse))\n",
    "    \n",
    "    # Step 6: Deploy the model to production\n",
    "    def deploy_model(model):\n",
    "        # Define a Kubernetes deployment resource as a YAML string\n",
    "        deployment_yaml = f\"\"\"\n",
    "        apiVersion: apps/v1\n",
    "        kind: Deployment\n",
    "        metadata:\n",
    "          name: mnist-model\n",
    "        spec:\n",
    "          replicas: 1\n",
    "          selector:\n",
    "            matchLabels:\n",
    "              app: mnist-model\n",
    "          template:\n",
    "            metadata:\n",
    "              labels:\n",
    "                app: mnist-model\n",
    "            spec:\n",
    "              containers:\n",
    "                - name: mnist-model\n",
    "                  image: gcr.io/my-project/mnist-model:latest  # Replace with your image\n",
    "        \"\"\"\n",
    "        \n",
    "        # Apply the Kubernetes deployment using kubectl\n",
    "        deploy_op = ContainerOp(\n",
    "            name=\"apply-k8s-deployment\",\n",
    "            image=\"lachlanevenson/k8s-kubectl:v1.18.8\",  # Replace with an appropriate kubectl image\n",
    "            command=[\"kubectl\", \"apply\", \"-f\", \"-\"],\n",
    "        )\n",
    "        \n",
    "        # Define the dependency on the previous step\n",
    "        deploy_op.after(train_model)\n",
    "\n",
    "    # Step 7: Create the pipeline steps\n",
    "    df = create_dataframe()\n",
    "    train_df, test_df = split_dataframe(df)\n",
    "    scaled_train_df = scale_features(train_df)\n",
    "    model = train_model(scaled_train_df)\n",
    "    evaluate_model(model, test_df)\n",
    "    \n",
    "    # Step 8: Deploy the model (make sure it's the last step)\n",
    "    deploy_model(model)\n",
    "    \n",
    "# Run the pipeline\n",
    "if __name__ == '__main__':\n",
    "    kfp.compiler.Compiler().compile(mnist_training_pipeline, 'mnist_training_pipeline.yaml')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36232c56",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
